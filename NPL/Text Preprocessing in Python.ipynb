{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it requires alot for me as karimi christine to  make a greate break in this ai field'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We lowercase the text to reduce the size of the vocabulary of our text data.\n",
    "def text_lower(text):\n",
    "    return text.lower()\n",
    "input_string='IT requires alot for me as karimi christine to  make a greate break in this AI Field'\n",
    "text_lower(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It requires to be among  , , , or  ,  individuals to   form acrowd'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can either remove numbers or convert the numbers into their textual representations. \n",
    "def remove_numb(text):\n",
    "    results=re.sub(r'\\d+', \" \" ,text)\n",
    "    return results\n",
    "input_str='It requires to be among 1,2,3, or 4,5 individuals to   form acrowd'\n",
    "remove_numb(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It require  streght motivation and the power the keep griding when nothing is working'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We remove punctuations so that we don’t have different forms of the same word. \n",
    "#If we don’t remove the punctuation, \n",
    "#then been. been, been! will be treated separately.\n",
    "def remove_put(text):\n",
    "    results=str.maketrans(\" \",\" \", string.punctuation)\n",
    "    return text.translate(results)\n",
    "input_text='It require , streght ,motivation ,and the power the keep griding when nothing is working!'\n",
    "remove_put(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it is called hard work to get through the initial state'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the join and split function to remove all the white spaces in a string.\n",
    "def remove_white(text):\n",
    "    return \" \".join(text.split())\n",
    "input_white=\"   it is called hard work to get through the initial state   \"\n",
    "remove_white(input_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['For',\n",
       " 'every',\n",
       " 'founder',\n",
       " 'owner',\n",
       " 'comapny',\n",
       " 'required',\n",
       " 'guts',\n",
       " ',',\n",
       " 'balls',\n",
       " 'go',\n",
       " 'take']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords are words that do not contribute to the meaning of a sentence. \n",
    "# Hence, they can safely be removed without causing any change in the meaning of the sentence.\n",
    "# The NLTK library has a set of stopwords and we can use these to remove \n",
    "# stopwords from our text and return a list of word tokens.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "def remove_stopwords(text):\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    word_toke=word_tokenize(text)\n",
    "    filterd_text=[ word for word in word_toke if word not in stop_words]\n",
    "    return  filterd_text\n",
    "sentense='For every founder or the owner of any comapny it required guts ,balls to go for what it take '\n",
    "remove_stopwords(sentense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so',\n",
       " 'it',\n",
       " 'realli',\n",
       " 'thi',\n",
       " 'easi',\n",
       " 'to',\n",
       " 'win',\n",
       " 'becaus',\n",
       " 'it',\n",
       " 'requir',\n",
       " 'work',\n",
       " 'hard',\n",
       " ',',\n",
       " 'high',\n",
       " 'pain',\n",
       " 'toler',\n",
       " 'danc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming is the process of getting the root form of a word. Stem or \n",
    "# root is the part to which inflectional affixes (-ed, -ize, -de, -s, etc.) are added. \n",
    "# The stem of a word is created by removing the \n",
    "# prefix or suffix of a word. So, stemming a word may not result in actual words.\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer=PorterStemmer()\n",
    "def word_stemm(text):\n",
    "    word_toke=word_tokenize(text)\n",
    "    stem=[stemmer.stem(word) for word in word_toke]\n",
    "    return stem\n",
    "Voice=\"So It really this easy to winning because it required  working hard  ,high pain tolerant danced \"\n",
    "word_stemm(Voice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So',\n",
       " 'It',\n",
       " 'really',\n",
       " 'this',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'win',\n",
       " 'because',\n",
       " 'it',\n",
       " 'require',\n",
       " 'work',\n",
       " 'hard',\n",
       " ',',\n",
       " 'high',\n",
       " 'pain',\n",
       " 'tolerant',\n",
       " 'dance']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "letimmer=WordNetLemmatizer()\n",
    "def word_let(text):\n",
    "    word_token=word_tokenize(text)\n",
    "    lemma=[letimmer.lemmatize(word,pos='v') for word in word_token]\n",
    "    return lemma\n",
    "words='So It really this easy to winning because it required  working hard  ,high pain tolerant danced'\n",
    "word_let(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('So', 'IN'),\n",
       " ('It', 'PRP'),\n",
       " ('really', 'RB'),\n",
       " ('this', 'DT'),\n",
       " ('easy', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('winning', 'VBG'),\n",
       " ('because', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('required', 'VBD'),\n",
       " ('working', 'VBG'),\n",
       " ('hard', 'RB'),\n",
       " (',', ','),\n",
       " ('high', 'JJ'),\n",
       " ('pain', 'NN'),\n",
       " ('tolerant', 'NN'),\n",
       " ('danced', 'VBD')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Speech Tagging:\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "def post_word(text):\n",
    "    word_token=word_tokenize(text)\n",
    "    return pos_tag(word_token)\n",
    "word='So It really this easy to winning because it required  working hard  ,high pain tolerant danced'\n",
    "post_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "#extracting information form the tag\n",
    "\n",
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
